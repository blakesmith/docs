==Use case 1 (microinverters)
Sensors:
 Status
 DC Power
 AC Power
 Efficiency
 Frequency
 Voltage
 Internal Temperature
 Cumulative energy
 Alarm states



Global rules configured across all devices

- Connectivity alert: For a device, alert if no data received for X minutes
    - Return device ID and # of minutes silent (& limit value)

- Sensor failure: reports a value outside "realistic" range (<Y or >Z), or if no data received for X minutes. All parameterized per-sensor.
    - Return device, sensor ID, value (& limit), or silence time (& limit)

- Overheat: Internal temp > 65C
- System error: Status > 1 - Need to know value.
- Voltage swell: 5-min moving avg. of voltage > 125

- Systemic inverter error: freq sensor is inaccurate, but if several inverters in an installation have freq outside typical range, then there's a real problem.
    * Aggregate threshold alert.

- Underperforming relative to expected efficiency: Given a DC power level, we know how efficient the inverter should be (or expected value of AC power). Piecewise linear fn.
Alert if more than X% away from expected.
    * Device-scope computation. Sensor(s) from a single device yield a new data stream scoped to the same device.

- Underperformance relative to other panels in installation: (E.g. over 30+ minutes) Might not be an error, but important to know about.
Alert if underperforms by X% for Y minutes. Or for Z% of the last Y minutes.
    * Aggregation computation. Sensor(s) from multiple devices are merged together in some way to represent a value scoped to that group of devices.


- Underperforming relative to measured irradiance. Given a solar irradiance value (measured outside the device), we know how much DC power should be generated (panel efficiency).
    * Device-scoped computation with external inputs. Result is scoped to a device, but requires sensor from outside the device.
    * How to find external input for a given device?


- Performance vs. max potential irradiance. Given lat/lng, datetime, and panel orientation, we can model expected irradiance and therefore production.
If deviation between expected production and actual is > X% AND if expected prod is > Y Watts, then alert.
    * Modeled production is scoped to device, but with no inputs from device. All fixed parameters. When to recompute?

- Installation underperforms relative to nearby installs: Each installation has a set of other installations that are nearby (region attribute).
They should be subject to roughly the same weather, sun exposure, etc. so energy production should be correlated. Each region has an expected
production (normalized... per sqft panel). Mean, max, or 90% of production in the region. Highlight installations which are < E% of expected production.
    * ?!?!?! comparing one aggregation computation to another with a different scope!!

- Alert if data coming from a device that isn't known or configured properly. Alert on _non-existance_ of an attribute?

-

For a lot of these, time window invariant. Can do over months, day, hour, minute. Shorter time ranges provide faster feedback, but greater chance of noise/false positives
(Meshulam's uncertainty principle)


=== Random q's
Condition to alert on every change? Only makes sense for enum values
Severity: based on higher thresholds, or # of alerts or time in alert state

Is moving avg truly part of a monitor? Not a clear distinction btwn calculations and monitors

Considerations specific to a realtime system:
- Maintaining state.
- Anything that can be done in realtime can be done over historical data. Inverse not true.


Specific to alerting (single stream of ts-values in, state change out)
- Balance reactivity with false positives. Different methods: M of N, moving average,
- Express severity
- Relevant to have multiple ts-value streams in? Compound conditions (And/Or)? Comparators are necessary.

I'm more convinced than ever  that monitoring without computation streams is cart before the horse. Separate the two and figure out what's required
in computations. Alerts are a very low-fi way to monitor what's going on.

Storing history of alerts is an optimization. Should be able to reconstruct them from raw data (like rollups). Breaks down if rule changes params
or if data is updated/written out of order.
Really 2 different uses for alert history. 1: record of what webhooks were sent out (even if updated data/rule renders them invalid)
2: did past data corespond to (potentially arbitrary) alert condition?

===What we don't know
- How persistent are monitoring rules? Do they get changed/deleted frequently or does a rule always have the same semantics?
- Rules for how streams work:
    - when data's out of order
    - when a stream doesn't exist
    - when no past data to seed


Types of stream selectors (Device=>Stream):
- By sensor ID
- By sensor attrs (pick one)

Device mapping node (Device=>Device)










==Use case 2 (smart home)

__Per house__
Water Usage
Electricity main
Electricity Hot water
Electricity MVHR
Master switch
Air temp house
Hot water temperature
Hot water boost
Immersion1
Immersion2

__Block wide or Sitewide__
Solar PV Excess
Solar PV
Air temp external


- 10 alerts for common faults and conditions are configured globally. These rules are mainly simple threshold rules on one or two sensors.
For each alert, notification needs to contain house ID and type of alert. (Metadata on monitoring rules?)


- Each non-switch sensor (5-20 per house) is being monitored for how recently it's received a data point, so that failures of individual sensors can be detected.
Need to know house, sensor, last point received.


- Individual users may configure an additional 5 threshold/moving average rules.

